# 提示词优化

请你根据上一步骤分析出的 Agent 架构，优化每个 Agent 的提示词，确保每个 Agent 的功能描述清晰、准确。

请根据 **用户需求** 与 **Agent 系统架构**，来优化每个 Agent 的系统提示词以及相关的工具描述。注意，生成的语言请以用户语言为主：如果用户主要语言是英文，那么生成的系统提示词也必须是英文了；反之如果用户主要语言是中文，那么生成的系统提示词也必须是中文。

下面是一份系统提示（System Prompt）工程的完整指南，系统性地讲解了如何设计、维护和演进高质量、可靠、可控且安全的 AI 系统提示词：

一、系统提示的基本原则

清晰与精确：避免模糊指令，像写“合同”一样写提示，减少歧义。

具体与灵活的平衡：既要约束行为，又不能过度“硬编码”，为模型保留推理空间。

明确上下文与边界：清楚规定“能做什么 / 不能做什么”，防止越界。

预判失败与边缘情况：提前设计好危险、伦理或模糊场景的应对方式。

二、理解模型本身

不同模型能力不同，对指令的理解深度、稳定性各异。

模型依赖训练数据进行模式匹配，并非真正“理解”。

Token 和上下文窗口有限，关键指令要靠前、简洁。

三、系统提示的架构设计

分层结构：身份 → 能力 → 边界 → 格式 → 兜底策略。

关注点分离：行为（语气）、知识范围、安全规则分开设计。

结构化表达：使用 Markdown、标签（类似 XML）帮助模型“分块理解”。

模块化与可维护性：像软件一样组合、复用、版本化提示。

指令优先级与冲突解决：明确“谁覆盖谁”，避免矛盾指令。

四、行为工程（Behavioral Engineering）

人格与语气设计：不同角色需要一致、可信的“性格”。

专业与亲和力平衡：既可信，又不冷漠。

文化敏感性与包容性：避免俚语、刻板印象，适配全球用户。

决策与推理框架：教模型如何处理不确定性、列出假设、再下结论。

升级与退出机制：知道什么时候拒绝、转人工、给资源而不是“硬答”。

综上，系统提示需要像代码一样需要结构、测试和维护；又像写剧本一样塑造角色、语气与边界。
